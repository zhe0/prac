{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhe0/prac/blob/main/untitle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install and import"
      ],
      "metadata": {
        "id": "CbRZZmv6frvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "%pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "%pip install transformers --upgrade\n",
        "%pip install datasets"
      ],
      "metadata": {
        "id": "9HLuHKetH3Lh"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "print(f\"Major: {major_version}, Minor: {minor_version}\")\n",
        "import os, gc\n",
        "import numpy as np\n",
        "from typing import Tuple, Any, Dict, List, Union\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "from huggingface_hub import login\n",
        "t='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'\n",
        "login(token = t)"
      ],
      "metadata": {
        "id": "CEMVH-UgrZ8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27faea4e-2727-424d-eb9d-f539250de49e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Major: 7, Minor: 5\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## read training data"
      ],
      "metadata": {
        "id": "E79wiajgR39J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "d=pd.read_excel('診斷證明書_手術資料表(至0209，尾巴多加三筆)_v0.1.xlsx',dtype=str)#,encoding='utf-8'\n",
        "d.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CCPyzQfSTZih",
        "outputId": "403e7385-852a-4ae4-bed6-9c6b214e45f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         理賠案號                                         診斷-病名  \\\n",
              "0  10900P4021                          妊娠38+3週合併胎位不正~(以下空白)   \n",
              "1  10900P4380                                    產程遲滯(以下空白)   \n",
              "2  10900P4682                      懷孕39週，早期破水胎位不正，剖腹產(以下空白)   \n",
              "3  10904G3287  右膝2公分撕裂傷縫合3針自109-12-15至109-12-28止共治療8次。以下空白。   \n",
              "4  10907F8611                             足月妊娠合併胎位不正。(以下空白)   \n",
              "\n",
              "                                                  醫囑  健保手術代碼  \\\n",
              "0  病患因上述原因於民國109年11月30日在本院住院，於民國109年12月01日剖腹生產，於民...  81011C   \n",
              "1  患者於民國109年12月15日入院待產，隔日因上述診斷剖腹產下壹名男嬰，於民國109年12月...  81011C   \n",
              "2  於109年12月18日入院，於109年12月19日接受剖腹產，109年12月13日出院，共計...  81011C   \n",
              "3                                                NaN  48001C   \n",
              "4  因上述原因，於民國109年11月16日入院，民國109年11月17日並行剖腹生產，並於民國1...  81011C   \n",
              "\n",
              "               健保手術名稱  \n",
              "0         有妊娠併發症之剖腹產術  \n",
              "1         有妊娠併發症之剖腹產術  \n",
              "2         有妊娠併發症之剖腹產術  \n",
              "3  淺部創傷處理 － 傷口長小於五公分者  \n",
              "4         有妊娠併發症之剖腹產術  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2a43fb6-f4fd-4715-a165-808961dceb0e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>理賠案號</th>\n",
              "      <th>診斷-病名</th>\n",
              "      <th>醫囑</th>\n",
              "      <th>健保手術代碼</th>\n",
              "      <th>健保手術名稱</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10900P4021</td>\n",
              "      <td>妊娠38+3週合併胎位不正~(以下空白)</td>\n",
              "      <td>病患因上述原因於民國109年11月30日在本院住院，於民國109年12月01日剖腹生產，於民...</td>\n",
              "      <td>81011C</td>\n",
              "      <td>有妊娠併發症之剖腹產術</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10900P4380</td>\n",
              "      <td>產程遲滯(以下空白)</td>\n",
              "      <td>患者於民國109年12月15日入院待產，隔日因上述診斷剖腹產下壹名男嬰，於民國109年12月...</td>\n",
              "      <td>81011C</td>\n",
              "      <td>有妊娠併發症之剖腹產術</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10900P4682</td>\n",
              "      <td>懷孕39週，早期破水胎位不正，剖腹產(以下空白)</td>\n",
              "      <td>於109年12月18日入院，於109年12月19日接受剖腹產，109年12月13日出院，共計...</td>\n",
              "      <td>81011C</td>\n",
              "      <td>有妊娠併發症之剖腹產術</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10904G3287</td>\n",
              "      <td>右膝2公分撕裂傷縫合3針自109-12-15至109-12-28止共治療8次。以下空白。</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48001C</td>\n",
              "      <td>淺部創傷處理 － 傷口長小於五公分者</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10907F8611</td>\n",
              "      <td>足月妊娠合併胎位不正。(以下空白)</td>\n",
              "      <td>因上述原因，於民國109年11月16日入院，民國109年11月17日並行剖腹生產，並於民國1...</td>\n",
              "      <td>81011C</td>\n",
              "      <td>有妊娠併發症之剖腹產術</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2a43fb6-f4fd-4715-a165-808961dceb0e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a2a43fb6-f4fd-4715-a165-808961dceb0e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a2a43fb6-f4fd-4715-a165-808961dceb0e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-116540e7-b762-47b0-aff3-f85716be6c61\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-116540e7-b762-47b0-aff3-f85716be6c61')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-116540e7-b762-47b0-aff3-f85716be6c61 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "d",
              "summary": "{\n  \"name\": \"d\",\n  \"rows\": 6282,\n  \"fields\": [\n    {\n      \"column\": \"\\u7406\\u8ce0\\u6848\\u865f\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5172,\n        \"samples\": [\n          \"1100106908\",\n          \"1100108821\",\n          \"1100120088\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u8a3a\\u65b7-\\u75c5\\u540d\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4694,\n        \"samples\": [\n          \"1.\\u5fc3\\u7d5e\\u75db.2.\\u5fc3\\u81df\\u8870\\u7aed\\u3002 (\\u4ee5\\u4e0b\\u7a7a\\u767d)\",\n          \"\\u53f3\\u5074\\u8179\\u80a1\\u6e9d\\u759d\\u6c23(\\u4ee5\\u4e0b\\u7a7a\\u767d)\\u53f3\\u5074\\u7cbe\\u7d22\\u8102\\u80aa\\u7624(\\u4ee5\\u4e0b\\u7a7a\\u767d)\",\n          \"\\u8180\\u80f1\\u764c. (\\u4ee5\\u4e0b\\u7a7a\\u767d)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u91ab\\u56d1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5125,\n        \"samples\": [\n          \"110\\u5e745\\u670824\\u65e5\\u4f4f\\u9662\\u884c\\u9aa8\\u6298\\u5fa9\\u4f4d\\u53ca\\u5916\\u56fa\\u5b9a\\u624b\\u8853\\uff0c110\\u5e745\\u670827\\u65e5\\u51fa\\u9662\\uff0c\\u9580\\u8a3a\\u8ffd\\u8e64\\u6cbb\\u7642\\u3002\\u81f3110\\u5e745\\u670831\\u65e5\\u5171\\u9580\\u8a3a\\u6cbb\\u76424\\u6b21\\u3002\\u3010\\u4ee5\\u4e0b\\u7a7a\\u767d\\u3011\",\n          \"\\u75c5\\u60a3\\u56e0\\u4e0a\\u8ff0\\u8a3a\\u65b7\\uff0c\\u65bc\\u6c11\\u570b110\\u5e7411\\u670815\\u65e5\\u81f3\\u672c\\u9662\\u9580\\u8a3a\\u6c42\\u6cbb\\uff0c\\u6c11\\u570b110\\u5e7411\\u670822\\u65e5\\u4f4f\\u9662\\u6cbb\\u7642\\uff0c\\u4e26\\u540c\\u5929\\u65bd\\u884c\\u95dc\\u7bc0\\u93e1\\u624b\\u8853\\u6cbb\\u7642\\uff0c\\u6c11\\u570b110\\u5e7411\\u670825\\u65e5\\u51fa\\u9662\\uff1b\\u7e8c\\u9580\\u8a3a\\u8ffd\\u8e64\\u8207\\u6cbb\\u7642\\uff1b\\u5b9c\\u4f11\\u990a \\u58f9\\u500b\\u6708\\u3002(\\u4ee5\\u4e0b\\u7a7a\\u767d)\",\n          \"\\u75c5\\u60a3\\u65bc110\\u5e743\\u670830\\u65e5\\u4f4f\\u9662\\uff0c110\\u5e743\\u670831\\u65e5\\u884c\\u8179\\u8154\\u93e1\\u6b21\\u5168\\u5b50\\u5bae\\u5207\\u9664\\u624b\\u8853\\uff0c\\u8853\\u4e2d\\u653e\\u7f6e\\u9632\\u6cbe\\u9ecfInterceed\\uff0c110\\u5e744\\u67082\\u65e5\\u51fa\\u9662\\uff0c\\u5171\\u4f4f\\u96624\\u65e5\\u3002\\u8853\\u5f8c\\u8fd4\\u8a3a\\u4e00\\u500b\\u6708(\\u4ee5\\u4e0b\\u7a7a\\u767d)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u5065\\u4fdd\\u624b\\u8853\\u4ee3\\u78bc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 168,\n        \"samples\": [\n          \"80412B\",\n          \"77026B\",\n          \"73013B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u5065\\u4fdd\\u624b\\u8853\\u540d\\u7a31\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 168,\n        \"samples\": [\n          \"\\u5ee3\\u6cdb\\u6027\\u5168\\u5b50\\u5bae\\u5207\\u9664\\u8853\",\n          \"\\u8f38\\u5c3f\\u7ba1\\u93e1\\u53d6\\u77f3\\u8853\\u53ca\\u788e\\u77f3\\u8853\\uff0d \\u55ae\\u7d14\\u5167\\u8996\\u93e1\\u64cd\\u4f5c\\u65b9\\u5f0f\",\n          \"\\u964d\\u7d50\\u8178\\u6216\\u4e59\\u72c0\\u7d50\\u8178\\u5207\\u9664\\u8853\\u52a0\\u543b\\u5408\\u8853\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lb=d['健保手術代碼'].dropna().unique().tolist()\n",
        "lb.sort()\n",
        "'手術代碼總數',len(lb),'第一個&最後一個',lb[0],lb[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsf7bekFVeBo",
        "outputId": "5a1297b2-61e5-425b-db76-2d7ea67f911f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('手術代碼總數', 168, '第一個&最後一個', '18021B', '92063C')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "''' hint of alpaca formated prompts\n",
        "\n",
        "### Instruction:\n",
        "[在此處放置明確的指令或任務描述]\n",
        "\n",
        "### Input:\n",
        "[如果有額外的輸入或上下文,放在這裡。如果沒有,可以留空]\n",
        "\n",
        "### Response:\n",
        "[這裡是模型應該生成的目標輸出]\n",
        "\n",
        "使用 \"###\" 來分隔不同的部分可以幫助模型更好地識別結構。\n",
        "在Instruction部分使用明確的動詞開頭,如\"Write\", \"Analyze\", \"Explain\"等,可以幫助模型理解任務類型。\n",
        "在Input部分,如果有多個元素,可以使用編號列表來組織信息。\n",
        "在Response部分,可以使用 \"[BEGIN]\" 和 \"[END]\" 標記來明確指出回答的開始和結束。\n",
        "使用 \"<SYS>\" 和 \"</SYS>\" 標記來包裹系統級指令或元信息。\n",
        "'''\n",
        "\n",
        "# jsonl_example = [\n",
        "#   {\"text\": TEMPLATE.format(context=\"hint\", question=\"q1\", answer=\"a1\")},\n",
        "#   {\"text\": TEMPLATE.format(context=\"hint\", question=\"q2\", answer=\"a2\")},\n",
        "#   {\"text\": TEMPLATE.format(context=\"hint\", question=\"q3\", answer=\"a3\")},\n",
        "# ]\n",
        "```"
      ],
      "metadata": {
        "id": "80Vh80QWaiYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chkValued=lambda x:x.notna().all()\n",
        "num=d['理賠案號'].unique().tolist()\n",
        "dd={}\n",
        "for n in num:\n",
        "    dd[n]={}\n",
        "    if chkValued(d[d['理賠案號']==n]['診斷-病名']):\n",
        "        dd[n]['診斷-病名']=d[d['理賠案號']==n]['診斷-病名'].tolist()[0]\n",
        "    else:\n",
        "        dd[n]['診斷-病名']=''\n",
        "    if chkValued(d[d['理賠案號']==n]['醫囑']):\n",
        "        dd[n]['醫囑']=d[d['理賠案號']==n]['醫囑'].tolist()[0]\n",
        "    else:\n",
        "        dd[n]['醫囑']=''\n",
        "    if chkValued(d[d['理賠案號']==n]['健保手術代碼']):\n",
        "        dd[n]['健保手術名稱']=', '.join(d[d['理賠案號']==n]['健保手術名稱'].tolist())\n",
        "        dd[n]['健保手術代碼']=', '.join(d[d['理賠案號']==n]['健保手術代碼'].tolist())\n",
        "    else:\n",
        "        dd[n]['健保手術名稱']=''\n",
        "        dd[n]['健保手術代碼']=''\n",
        "data={}\n",
        "data['data']=dd.keys()\n",
        "data['診斷-病名']=[dd[k]['診斷-病名'] for k in dd]\n",
        "data['醫囑']=[dd[k]['醫囑'] for k in dd]\n",
        "data['健保手術名稱']=[dd[k]['健保手術名稱'] for k in dd]\n",
        "data=pd.DataFrame(data)\n",
        "data"
      ],
      "metadata": {
        "id": "o8RGHLh-ngDl",
        "outputId": "339664c9-a08d-475d-fd76-92e6c943fae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            data                                         診斷-病名  \\\n",
              "0     10900P4021                          妊娠38+3週合併胎位不正~(以下空白)   \n",
              "1     10900P4380                                    產程遲滯(以下空白)   \n",
              "2     10900P4682                      懷孕39週，早期破水胎位不正，剖腹產(以下空白)   \n",
              "3     10904G3287  右膝2公分撕裂傷縫合3針自109-12-15至109-12-28止共治療8次。以下空白。   \n",
              "4     10907F8611                             足月妊娠合併胎位不正。(以下空白)   \n",
              "...          ...                                           ...   \n",
              "5167  1101019363                       1.雙側腎結石 2.左側輸尿管結石(以下空白)   \n",
              "5168  1101031234                                左手腕腱鞘囊腫。(以下空白)   \n",
              "5169  1101210040                左膝膕處微血管型血管瘤(1x1 cm x cm)-以下空白-   \n",
              "5170  11000N4878                            右肩滑液囊炎併腱鞘囊腫 [以下空白]   \n",
              "5171  11000R6716           1.泌尿道感染 2.膀胱結石 3.膀胱腫瘤 4.攝護腺增生(以下空白)   \n",
              "\n",
              "                                                     醫囑  \\\n",
              "0     病患因上述原因於民國109年11月30日在本院住院，於民國109年12月01日剖腹生產，於民...   \n",
              "1     患者於民國109年12月15日入院待產，隔日因上述診斷剖腹產下壹名男嬰，於民國109年12月...   \n",
              "2     於109年12月18日入院，於109年12月19日接受剖腹產，109年12月13日出院，共計...   \n",
              "3                                                         \n",
              "4     因上述原因，於民國109年11月16日入院，民國109年11月17日並行剖腹生產，並於民國1...   \n",
              "...                                                 ...   \n",
              "5167  病患因上述診斷於110年08月12日，110年08月26日，110年09月23日在門診複診，...   \n",
              "5168  病患於民國110年10月14日入院，於110年10月15日行腱鞘囊腫切除手術，於110年10...   \n",
              "5169                          20190509 行腫瘤切除及縫合手術-以下空白-   \n",
              "5170  病患因上述診斷於二零二一年十月十八日入院，十月十九日行滑液囊及腱鞘囊腫切除手術加羊膜異體移植...   \n",
              "5171  1.住院日自民國110年12月2日至民國110年12月7日，共計6天。2.民國110年12月...   \n",
              "\n",
              "                                            健保手術名稱  \n",
              "0                                      有妊娠併發症之剖腹產術  \n",
              "1                                      有妊娠併發症之剖腹產術  \n",
              "2                                      有妊娠併發症之剖腹產術  \n",
              "3                               淺部創傷處理 － 傷口長小於五公分者  \n",
              "4                                      有妊娠併發症之剖腹產術  \n",
              "...                                            ...  \n",
              "5167  碎石取出術、簡單（在膀胱內壓碎並除去）, 輸尿管鏡取石術及碎石術－ 併用超音波或電擊方式  \n",
              "5168                                                \n",
              "5169                                                \n",
              "5170                                                \n",
              "5171                                                \n",
              "\n",
              "[5172 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7b1ab58-3bae-49a0-87f8-1631fc32794e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>診斷-病名</th>\n",
              "      <th>醫囑</th>\n",
              "      <th>健保手術名稱</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10900P4021</td>\n",
              "      <td>妊娠38+3週合併胎位不正~(以下空白)</td>\n",
              "      <td>病患因上述原因於民國109年11月30日在本院住院，於民國109年12月01日剖腹生產，於民...</td>\n",
              "      <td>有妊娠併發症之剖腹產術</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10900P4380</td>\n",
              "      <td>產程遲滯(以下空白)</td>\n",
              "      <td>患者於民國109年12月15日入院待產，隔日因上述診斷剖腹產下壹名男嬰，於民國109年12月...</td>\n",
              "      <td>有妊娠併發症之剖腹產術</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10900P4682</td>\n",
              "      <td>懷孕39週，早期破水胎位不正，剖腹產(以下空白)</td>\n",
              "      <td>於109年12月18日入院，於109年12月19日接受剖腹產，109年12月13日出院，共計...</td>\n",
              "      <td>有妊娠併發症之剖腹產術</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10904G3287</td>\n",
              "      <td>右膝2公分撕裂傷縫合3針自109-12-15至109-12-28止共治療8次。以下空白。</td>\n",
              "      <td></td>\n",
              "      <td>淺部創傷處理 － 傷口長小於五公分者</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10907F8611</td>\n",
              "      <td>足月妊娠合併胎位不正。(以下空白)</td>\n",
              "      <td>因上述原因，於民國109年11月16日入院，民國109年11月17日並行剖腹生產，並於民國1...</td>\n",
              "      <td>有妊娠併發症之剖腹產術</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>1101019363</td>\n",
              "      <td>1.雙側腎結石 2.左側輸尿管結石(以下空白)</td>\n",
              "      <td>病患因上述診斷於110年08月12日，110年08月26日，110年09月23日在門診複診，...</td>\n",
              "      <td>碎石取出術、簡單（在膀胱內壓碎並除去）, 輸尿管鏡取石術及碎石術－ 併用超音波或電擊方式</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5168</th>\n",
              "      <td>1101031234</td>\n",
              "      <td>左手腕腱鞘囊腫。(以下空白)</td>\n",
              "      <td>病患於民國110年10月14日入院，於110年10月15日行腱鞘囊腫切除手術，於110年10...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5169</th>\n",
              "      <td>1101210040</td>\n",
              "      <td>左膝膕處微血管型血管瘤(1x1 cm x cm)-以下空白-</td>\n",
              "      <td>20190509 行腫瘤切除及縫合手術-以下空白-</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5170</th>\n",
              "      <td>11000N4878</td>\n",
              "      <td>右肩滑液囊炎併腱鞘囊腫 [以下空白]</td>\n",
              "      <td>病患因上述診斷於二零二一年十月十八日入院，十月十九日行滑液囊及腱鞘囊腫切除手術加羊膜異體移植...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5171</th>\n",
              "      <td>11000R6716</td>\n",
              "      <td>1.泌尿道感染 2.膀胱結石 3.膀胱腫瘤 4.攝護腺增生(以下空白)</td>\n",
              "      <td>1.住院日自民國110年12月2日至民國110年12月7日，共計6天。2.民國110年12月...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5172 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7b1ab58-3bae-49a0-87f8-1631fc32794e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b7b1ab58-3bae-49a0-87f8-1631fc32794e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b7b1ab58-3bae-49a0-87f8-1631fc32794e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7ed2d3b-976a-4c97-af2c-7c8f7b813499\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7ed2d3b-976a-4c97-af2c-7c8f7b813499')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7ed2d3b-976a-4c97-af2c-7c8f7b813499 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_41203579-f86b-4421-bed2-0bd93f010677\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_41203579-f86b-4421-bed2-0bd93f010677 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5172,\n  \"fields\": [\n    {\n      \"column\": \"data\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5172,\n        \"samples\": [\n          \"1100106908\",\n          \"1100108821\",\n          \"1100120088\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u8a3a\\u65b7-\\u75c5\\u540d\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4695,\n        \"samples\": [\n          \"(\\u5169\\u773c)\\u4e7e\\u773c\\u75c7\\u5f8c\\u7fa4\",\n          \"\\u9670\\u9053\\u8089\\u82bd\\u7d44\\u7e54\\u4f75\\u50b7\\u53e3\\u7652\\u5408\\u4e0d\\u826f(\\u4ee5\\u4e0b\\u7a7a\\u767d)\",\n          \"\\u611f\\u67d3\\u6027\\u8179\\u7009(\\u4ee5\\u4e0b\\u7a7a\\u767d)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u91ab\\u56d1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5125,\n        \"samples\": [\n          \"\\u75c5\\u4eba\\u65bc110\\u5e7404\\u670806\\u65e5\\u4f4f\\u9662\\uff0c\\u65bc110\\u5e7404\\u670812\\u65e5\\u63a5\\u53d7\\u816b\\u7624\\u5207\\u9664\\u624b\\u8853\\uff0c110\\u5e7404\\u670826\\u65e5\\u51fa\\u9662\\u3002110\\u5e7404\\u670801\\u65e5(\\u9aa8\\u79d1\\u90e8)\\u3001110\\u5e7404\\u670827\\u65e5(\\u816b\\u7624\\u79d1)\\u3001110\\u5e7405\\u670804\\u65e5(\\u816b\\u7624\\u79d1)\\u3001110\\u5e7405\\u670825\\u65e5(\\u9aa8\\u79d1\\u90e8)\\u9580\\u8a3a\\u3002\\u4ee5\\u4e0b\\u7a7a\\u767d\",\n          \"\\u53f0\\u5357\\u65b0\\u6a13\\u5c31\\u91ab\\u7d00\\u9304\\u6e05\\u55ae:(110-11-03~110-12-03) \\u9580\\u8a3a(4\\u6b21) \\u65e5\\u671f110-11-19.110-11-22.110-11-29.110-12-03 \\u91ab\\u5e2b \\u5442\\u654f\\u4e2d \\u4f4f\\u9662(1\\u6b21) \\u65e5\\u671f110-11-22~110-11-24 \\u91ab\\u5e2b \\u5442\\u654f\\u4e2d (\\u517103\\u5929) 110-11-23\\u63a5\\u53d7\\u8f38\\u5c3f\\u7ba1\\u93e1\\u6aa2\\u67e5\\u53ca\\u96d9J\\u7ba1\\u7f6e\\u5165\\u8853 110-11-30\\u62d4\\u9664\\u5de6\\u5074\\u96d9J\\u5c0e\\u7ba1\\u8853 \\u66fe\\u65bc110-11-30\\u81f3\\u6025\\u8a3a\\u6cbb\\u7642 (\\u4ee5\\u4e0b\\u7a7a\\u767d)\",\n          \"\\u75c5\\u4eba\\u56e0\\u4e0a\\u8ff0\\u539f\\u56e0\\uff0c\\u65bc\\u6c11\\u570b110\\u5e7403\\u670829\\u65e5\\u81f3\\u672c\\u9662\\u4f4f\\u9662\\uff0c\\u65bc\\u6c11\\u570b110\\u5e7403\\u670830\\u65e5\\u63a5\\u53d7\\u9838\\u690e\\u524d\\u8def\\u690e\\u9593\\u76e4\\u5207\\u9664\\u53ca\\u878d\\u5408\\u624b\\u8853\\uff0c\\u65bc\\u6c11\\u570b110\\u5e7404\\u670803\\u65e5\\u51fa\\u9662\\uff0c\\u8853\\u5f8c\\u5b9c\\u7a7f\\u6234\\u9838\\u5708\\u4e00\\u500b\\u6708\\uff0c\\u51fa\\u9662\\u5f8c\\u5b9c\\u5728\\u5bb6\\u4f11\\u990a\\u5169\\u9031\\uff0c\\u5b9c\\u65bc\\u9580\\u8a3a\\u6301\\u7e8c\\u8ffd\\u8e64\\u6cbb\\u7642\\u3002--\\u4ee5\\u4e0b\\u7a7a\\u767d--\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u5065\\u4fdd\\u624b\\u8853\\u540d\\u7a31\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 326,\n        \"samples\": [\n          \"\\u5341\\u4e8c\\u6307\\u8178\\u816b\\u7624\\u5207\\u9664\",\n          \"\\u7d93\\u8180\\u80f1\\u93e1\\u9006\\u884c\\u5c3f\\u7ba1\\u5c0e\\u7ba1\",\n          \"\\u55ae\\u5074\\u7532\\u72c0\\u817a\\u5168\\u8449\\u5207\\u9664\\u8853\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##set training params and load pretrained model"
      ],
      "metadata": {
        "id": "4OViUloBZ7m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "max_seq_length = 512 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype=torch.float16 # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True\n",
        "seed=3407\n",
        "rank=16\n",
        "lora_alpha=16\n",
        "repo_id='zhe0/outputs'\n",
        "model_name = 'shenzhi-wang/Llama3.1-8B-Chinese-Chat'#\"unsloth/Meta-Llama-3.1-8B-bnb-4bit\"\n",
        "resume=True #繼續接續訓練adapter"
      ],
      "metadata": {
        "id": "d82wblgUaFCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ec6253-61c9-44bf-bcc9-0359f1ee228f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "org, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    max_seq_length = max_seq_length,\n",
        ")\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    org,\n",
        "    r = rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = lora_alpha,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = seed,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "db3e51e0a8d244d7a53e9d50d2fce38c",
            "1d2c67d0758846c393fc8cbead19d456",
            "6b1d2a8a16524835b5e0b766beb4050f",
            "dcbd154bfbdc40edac55be9ab3843160",
            "c3bdacc96a6d4182b795b5f4dceefcf3",
            "27d88911ded34b5682a288af1fd589e3",
            "d758b1d96ad44a808bfaf8367c6d2cf6",
            "68787eff1105466a936f7fdc0407d6d1",
            "85bcd726079141f7ab4ce909629279a5",
            "0f20eeae80ac4e2d966844592b9dec01",
            "d45add3904234898bd48ea7fee34b706"
          ]
        },
        "id": "APE5Kl32Zjst",
        "outputId": "4eb3fa31-abf8-4b27-b02b-e572e825fe4d",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Fast Llama patching release 2024.8\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db3e51e0a8d244d7a53e9d50d2fce38c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "shenzhi-wang/Llama3.1-8B-Chinese-Chat does not have a padding token! Will use pad_token = <|reserved_special_token_247|>.\n",
            "Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm()\n",
              "            (post_attention_layernorm): LlamaRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm()\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_adapter(adapter_name=repo_id,model_id=repo_id)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_id3HeBD7s5",
        "outputId": "a8692f3c-4cba-41ee-8055-1d72452b38b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['base_model.model.model.embed_tokens.weight', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.0.input_layernorm.weight', 'base_model.model.model.layers.0.post_attention_layernorm.weight', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.input_layernorm.weight', 'base_model.model.model.layers.1.post_attention_layernorm.weight', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.2.input_layernorm.weight', 'base_model.model.model.layers.2.post_attention_layernorm.weight', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.3.input_layernorm.weight', 'base_model.model.model.layers.3.post_attention_layernorm.weight', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.4.input_layernorm.weight', 'base_model.model.model.layers.4.post_attention_layernorm.weight', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.5.input_layernorm.weight', 'base_model.model.model.layers.5.post_attention_layernorm.weight', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.6.input_layernorm.weight', 'base_model.model.model.layers.6.post_attention_layernorm.weight', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.7.input_layernorm.weight', 'base_model.model.model.layers.7.post_attention_layernorm.weight', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.8.input_layernorm.weight', 'base_model.model.model.layers.8.post_attention_layernorm.weight', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.9.input_layernorm.weight', 'base_model.model.model.layers.9.post_attention_layernorm.weight', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.10.input_layernorm.weight', 'base_model.model.model.layers.10.post_attention_layernorm.weight', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.11.input_layernorm.weight', 'base_model.model.model.layers.11.post_attention_layernorm.weight', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.12.input_layernorm.weight', 'base_model.model.model.layers.12.post_attention_layernorm.weight', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.13.input_layernorm.weight', 'base_model.model.model.layers.13.post_attention_layernorm.weight', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.14.input_layernorm.weight', 'base_model.model.model.layers.14.post_attention_layernorm.weight', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.15.input_layernorm.weight', 'base_model.model.model.layers.15.post_attention_layernorm.weight', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.16.input_layernorm.weight', 'base_model.model.model.layers.16.post_attention_layernorm.weight', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.17.input_layernorm.weight', 'base_model.model.model.layers.17.post_attention_layernorm.weight', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.18.input_layernorm.weight', 'base_model.model.model.layers.18.post_attention_layernorm.weight', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.19.input_layernorm.weight', 'base_model.model.model.layers.19.post_attention_layernorm.weight', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.20.input_layernorm.weight', 'base_model.model.model.layers.20.post_attention_layernorm.weight', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.21.input_layernorm.weight', 'base_model.model.model.layers.21.post_attention_layernorm.weight', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.22.input_layernorm.weight', 'base_model.model.model.layers.22.post_attention_layernorm.weight', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.23.input_layernorm.weight', 'base_model.model.model.layers.23.post_attention_layernorm.weight', 'base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.24.input_layernorm.weight', 'base_model.model.model.layers.24.post_attention_layernorm.weight', 'base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.25.input_layernorm.weight', 'base_model.model.model.layers.25.post_attention_layernorm.weight', 'base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.26.input_layernorm.weight', 'base_model.model.model.layers.26.post_attention_layernorm.weight', 'base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.27.input_layernorm.weight', 'base_model.model.model.layers.27.post_attention_layernorm.weight', 'base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.28.input_layernorm.weight', 'base_model.model.model.layers.28.post_attention_layernorm.weight', 'base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.29.input_layernorm.weight', 'base_model.model.model.layers.29.post_attention_layernorm.weight', 'base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.30.input_layernorm.weight', 'base_model.model.model.layers.30.post_attention_layernorm.weight', 'base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.31.input_layernorm.weight', 'base_model.model.model.layers.31.post_attention_layernorm.weight', 'base_model.model.model.norm.weight', 'base_model.model.lm_head.weight'], unexpected_keys=[])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare dataset"
      ],
      "metadata": {
        "id": "JcghBtYBN42n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prompt1"
      ],
      "metadata": {
        "id": "zXWKchFbg0qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "任務：從\"診斷病名\"與\"醫囑\"推論病患可能施行過那些\"醫療手術\"?\n",
        "提示：這是個多標籤分類任務: multi-label task，醫療手術可能0到多個手術\n",
        "\n",
        "### Input:\n",
        "診斷病名:\n",
        "{disease}\n",
        "醫囑:\n",
        "{doc}\n",
        "\n",
        "### Response:\n",
        "{ans}\"\"\"\n",
        "\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "EOS='<|eot_id|><|end_of_text|><|end_of_text|>'\n",
        "loop=data[['診斷-病名','醫囑','健保手術名稱']].values"
      ],
      "metadata": {
        "id": "KBfdj9BPg8pY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "jsonl=[{\n",
        "  'text': alpaca_prompt.format(disease=i,doc=j,ans=k)+EOS\n",
        "  } for i,j,k in loop]\n",
        "\n",
        "my_dataset = Dataset.from_list(jsonl)\n",
        "print('dataset summary',my_dataset)\n",
        "\n",
        "# to check training data\n",
        "my_dataset.data[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnx-t1nQjtOs",
        "outputId": "ffbce39b-9b23-4bed-fd0a-3eee7ac95f54"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset summary Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 5172\n",
            "})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.StringScalar: 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n任務：從\"診斷病名\"與\"醫囑\"推論病患可能施行過那些\"醫療手術\"?\\n提示：這是個多標籤分類任務: multi-label task，醫療手術可能0到多個手術\\n\\n### Input:\\n診斷病名:\\n妊娠38+3週合併胎位不正~(以下空白)\\n醫囑:\\n病患因上述原因於民國109年11月30日在本院住院，於民國109年12月01日剖腹生產，於民國109年12月06日出院，宜於門診持續追蹤治療~(以下空白)\\n\\n### Response:\\n有妊娠併發症之剖腹產術<|eot_id|><|end_of_text|><|end_of_text|>'>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prompt2 (not succ)"
      ],
      "metadata": {
        "id": "9VpcEclogsV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "TEMPLATE = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "{context}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "{answer}<|eot_id|>\"\"\"\n",
        "\n",
        "context='這是個醫療問題，從\"診斷病名\"與\"醫囑\"推論找出哪些\"醫療手術\"?，醫療手術可能0到多個，可以理解為多標籤分類任務: multi-label task'\n",
        "question='根據診斷病名與醫囑的資訊推論執行哪些醫療手術?\\n診斷病名:\\n{disease}\\n醫囑{doc}:\\n'\n",
        "loop=data[['診斷-病名','醫囑','健保手術名稱']].values\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "jsonl=[{\n",
        "  'text': TEMPLATE.format(context=context,question=question.format(disease=i,doc=j),answer=k)+EOS_TOKEN\n",
        "  } for i,j,k in loop]\n",
        "\n",
        "my_dataset = Dataset.from_list(jsonl)\n",
        "print('dataset summary',my_dataset)\n",
        "\n",
        "# to check training data\n",
        "my_dataset.data[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS_i5EBbN7hZ",
        "outputId": "52273713-d70f-4af3-9ce8-a695a79fa3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset summary Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 5172\n",
            "})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.StringScalar: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n這是個醫療問題，從\"診斷病名\"與\"醫囑\"推論找出哪些\"醫療手術\"?，醫療手術可能0到多個，可以理解為多標籤分類任務: multi-label task<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n根據診斷病名與醫囑的資訊推論執行哪些醫療手術?\\n診斷病名:\\n妊娠38+3週合併胎位不正~(以下空白)\\n醫囑病患因上述原因於民國109年11月30日在本院住院，於民國109年12月01日剖腹生產，於民國109年12月06日出院，宜於門診持續追蹤治療~(以下空白):\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n有妊娠併發症之剖腹產術<|eot_id|><|end_of_text|>'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## start to train"
      ],
      "metadata": {
        "id": "KL8eWtv5cy6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "batch_size=6 #16@rank8、\n",
        "packing=True, # Can make training 5x faster for short sequences."
      ],
      "metadata": {
        "id": "4STHs_2va317"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = my_dataset,\n",
        "    eval_dataset = my_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = os.cpu_count(),\n",
        "    packing = packing,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = batch_size,\n",
        "        # gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        # max_steps = 60,\n",
        "        learning_rate = 8e-5,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = seed,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "2lay9IaQIoyl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()#resume_from_checkpoint=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i1cMPbw_Iot-",
        "outputId": "b20e590d-4cf7-4669-98dd-001ff3125bdb",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 2,258 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 6 | Gradient Accumulation steps = 1\n",
            "\\        /    Total batch size = 6 | Total steps = 377\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='377' max='377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [377/377 51:46, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.378000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.539700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.378300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.258800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.322800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.242400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.140700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.858600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.980100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.796000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.732300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.719900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.596800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.511500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.503500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.459400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.343100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.342900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.322300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.284500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.443400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.149000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.107900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.105700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.021500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.174100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.865500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.888900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.051400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.765800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.041200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.861000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.012100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.965300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.014700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.973600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.885000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.776100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.009500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.902700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.856000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.993200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.995500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.831500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.888100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.879300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.878900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.036500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.731300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.880300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.187600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.849600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.952700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.946600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.815000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.854000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.929800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.812000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.763000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.837300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.813200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.742700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.846100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.827700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.718500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.116800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.739400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.743800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.624900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.704800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.673700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.810100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.656100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.921800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.840200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.276900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.926900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.689900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.685700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.825400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.758600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.754800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.779700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.848400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.930700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.783500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.784100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.810300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.698400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.844300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.732200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.681100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.782600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.847500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.735800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.706700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.773700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.633900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>0.664300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.761900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.639100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.742400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.656000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>0.777900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>0.799700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.867800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.616500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.633500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.746000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.596900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>0.703700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.629500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.686300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.665900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.883900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.739100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.777000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.665700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.904300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.674100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.686700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>0.824700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.712400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>0.701000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>0.629600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.736300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>0.702000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.842800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>0.613100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>0.718300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>0.664700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>0.697900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.627900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>0.653100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>0.671200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>0.815600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>0.771200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.819000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.710700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>0.583400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>0.734800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.598500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.601700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>0.611200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.707800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>0.678500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>0.654100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.749100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>0.525300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>0.651400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>0.752000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>0.624600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.659300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>0.607300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.586200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.556500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.727700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>0.570700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>0.680600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>0.600700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>0.706800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.720900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>0.643800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>0.675100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.590400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.584500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.724100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>0.631200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>0.696400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>0.851600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.743900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.621400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>0.558000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>0.692700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>0.674200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>0.695300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.695500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>0.764100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>0.643400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>0.597500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>0.575300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.580100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.688800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>0.778200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>0.663400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>0.653700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.723400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>0.739200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.601600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>0.564200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>0.605500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.869200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>0.713800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.578800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>0.672300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>0.648200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.626400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>0.779300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>0.628400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>0.680800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>0.643400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.777300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>0.614200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>0.652000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>0.487200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>0.575700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.565700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>0.756300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>0.572600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>0.595800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>0.630300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.619500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.557100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>0.700500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>0.779500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>0.692600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.561200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>0.551300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>0.680900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>0.770000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>0.725200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.585500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>0.665700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>0.631200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>0.581500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>0.550500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.658400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>0.760800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>0.613300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>0.573900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.656600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>0.653500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>0.613100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>0.714200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>0.585700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>0.579000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.581200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>0.600100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>0.667700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>0.574500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>0.648300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.676500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>0.709400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>0.662300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>248</td>\n",
              "      <td>0.671800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>0.542400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.548600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>251</td>\n",
              "      <td>0.531200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>0.541700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>253</td>\n",
              "      <td>0.666700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>254</td>\n",
              "      <td>0.627700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.567000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>256</td>\n",
              "      <td>0.565900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>257</td>\n",
              "      <td>0.804500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>0.628600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>259</td>\n",
              "      <td>0.589700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.547400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>261</td>\n",
              "      <td>0.680300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>262</td>\n",
              "      <td>0.595100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>263</td>\n",
              "      <td>0.610600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>0.721100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>0.709300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>266</td>\n",
              "      <td>0.542400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>267</td>\n",
              "      <td>0.571100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>268</td>\n",
              "      <td>0.599100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>269</td>\n",
              "      <td>0.652500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.684300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>271</td>\n",
              "      <td>0.593400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>272</td>\n",
              "      <td>0.600900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>0.562700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>274</td>\n",
              "      <td>0.844500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.512900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>0.577900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>277</td>\n",
              "      <td>0.523400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>278</td>\n",
              "      <td>0.559800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.632800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.592900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>281</td>\n",
              "      <td>0.781200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>282</td>\n",
              "      <td>0.673600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>283</td>\n",
              "      <td>0.567200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>284</td>\n",
              "      <td>0.627600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.600500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>286</td>\n",
              "      <td>0.724500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>287</td>\n",
              "      <td>0.693500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>0.671700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>289</td>\n",
              "      <td>0.520800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.613300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>291</td>\n",
              "      <td>0.571200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>292</td>\n",
              "      <td>0.552000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>293</td>\n",
              "      <td>0.655100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>294</td>\n",
              "      <td>0.602900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>0.609900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>296</td>\n",
              "      <td>0.782400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>0.603800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>298</td>\n",
              "      <td>0.595700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>299</td>\n",
              "      <td>0.671500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.586300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>301</td>\n",
              "      <td>0.494200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>302</td>\n",
              "      <td>0.588900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>303</td>\n",
              "      <td>0.557900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>304</td>\n",
              "      <td>0.609400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>0.656500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>306</td>\n",
              "      <td>0.574300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>307</td>\n",
              "      <td>0.539100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>308</td>\n",
              "      <td>0.612600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>309</td>\n",
              "      <td>0.564700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.606700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>311</td>\n",
              "      <td>0.728800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>312</td>\n",
              "      <td>0.534400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>313</td>\n",
              "      <td>0.577900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>314</td>\n",
              "      <td>0.576100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>0.658700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>316</td>\n",
              "      <td>0.602200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>317</td>\n",
              "      <td>0.560500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>318</td>\n",
              "      <td>0.589100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>319</td>\n",
              "      <td>0.591700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.583700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>321</td>\n",
              "      <td>0.669800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>322</td>\n",
              "      <td>0.586900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>323</td>\n",
              "      <td>0.634900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>324</td>\n",
              "      <td>0.694100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.537300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>326</td>\n",
              "      <td>0.689800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>327</td>\n",
              "      <td>0.641000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>328</td>\n",
              "      <td>0.665500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>329</td>\n",
              "      <td>0.549400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.554200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>331</td>\n",
              "      <td>0.653100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>332</td>\n",
              "      <td>0.659700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>333</td>\n",
              "      <td>0.708000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>334</td>\n",
              "      <td>0.517000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>335</td>\n",
              "      <td>0.586600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>336</td>\n",
              "      <td>0.692300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>337</td>\n",
              "      <td>0.708900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>338</td>\n",
              "      <td>0.627100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>339</td>\n",
              "      <td>0.570200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.558400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>341</td>\n",
              "      <td>0.634100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>342</td>\n",
              "      <td>0.480400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>343</td>\n",
              "      <td>0.653600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>344</td>\n",
              "      <td>0.722700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.538200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>346</td>\n",
              "      <td>0.864200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>347</td>\n",
              "      <td>0.611000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>348</td>\n",
              "      <td>0.660400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>349</td>\n",
              "      <td>0.565500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.539100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>351</td>\n",
              "      <td>0.593500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>352</td>\n",
              "      <td>0.600900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>353</td>\n",
              "      <td>0.525900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>354</td>\n",
              "      <td>0.793200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>355</td>\n",
              "      <td>0.620600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>356</td>\n",
              "      <td>0.612400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>357</td>\n",
              "      <td>0.702300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>358</td>\n",
              "      <td>0.667000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>359</td>\n",
              "      <td>0.577200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.524800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>361</td>\n",
              "      <td>0.565900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>362</td>\n",
              "      <td>0.591800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>363</td>\n",
              "      <td>0.705500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>364</td>\n",
              "      <td>0.553700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>365</td>\n",
              "      <td>0.551600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>366</td>\n",
              "      <td>0.526000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>367</td>\n",
              "      <td>0.736500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>368</td>\n",
              "      <td>0.612300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>369</td>\n",
              "      <td>0.606500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.574100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>371</td>\n",
              "      <td>0.600300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.589100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>373</td>\n",
              "      <td>0.539400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>374</td>\n",
              "      <td>0.585800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.699800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>376</td>\n",
              "      <td>0.734200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>377</td>\n",
              "      <td>0.807800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save to hug hub"
      ],
      "metadata": {
        "id": "pNK5aS-_UXFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.model.push_to_hub(repo_id,use_auth_token=t,tokenizer=tokenizer)\n",
        "# trainer.push_to_hub(repo_id)\n",
        "trainer.model.push_to_hub('outputs',use_temp_dir=False) #經由hug toke login in 之後可不帶參數\n",
        "# model.push_to_hub(repo_id)\n",
        "# tokenizer.push_to_hub(repo_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "1ce5f5f73c2a4234bbe185fd41b49c62",
            "b6dcf66294c84140b70a97efdd1a4a08",
            "59346db034ff48f290df7b8e172a296c",
            "1a5226cb80674f5bbdc4995e4e280615",
            "c21481dd9bd34c7ab6363b5540538d31",
            "f8fa2a0ee6904539a28be2ac68de2f0a",
            "41067882276e4ccb8c307b50f5dd1240",
            "72d3b6b36adc439f8d3a4a30c2a2e6bd",
            "90257f549711488c93745fb1b6d2d74a",
            "f0a340fed4f747deb38d8ac4fd3ce53b",
            "eecfef45bf3e4440885b4c19b23034ba",
            "5503aac04d4c48a8b1551427e74bf9f4",
            "8e1027e0e0d4474b8be12c55d7aba0c2",
            "37bd70a51c93480e9b4b4cf11d3c17dc",
            "4d56cc1134b34e81ac0f29601ad7c5fe",
            "41f4cda132c248b1b6b437d83f1e45c1",
            "cab1cfd0ef024464b61e4076f83472d0",
            "d67609726aba4bc6a0feeef47cdbba63",
            "43e8a32a4d4549968d5e38514bd3d217",
            "7ede50eef0cd420c81bfd4fb99d040d0",
            "a8a7ebcea0684bc0b486859871edf1cd",
            "84a7f27933e246c2ae59cdd4548dac8f"
          ]
        },
        "id": "s6_Ck90Uf-SE",
        "outputId": "eb05a1de-ff53-4ed3-e32a-12fdf420e837"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ce5f5f73c2a4234bbe185fd41b49c62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5503aac04d4c48a8b1551427e74bf9f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to https://huggingface.co/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inf test"
      ],
      "metadata": {
        "id": "S8oQfT1to2hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "\n",
        "_disease='懷孕39週，早期破水胎位不正，剖腹產(以下空白)'\n",
        "_doc='於109年12月18日入院，於109年12月19日接受剖腹產，109年12月13日出院，共計6天.(以下空白)'\n",
        "# _disease='1.頭部外傷併腦震盪及右眼皮(1公分)，下巴(1公分)，舌頭撕裂傷(2公分)2.多處擦傷3.左上門牙部分斷裂(以下空白)'\n",
        "# _doc='病患因以上病因於2020/12/11至本院急診，於急診接受右眼皮，下巴，舌頭撕裂傷縫合術，2020/12/11住院，2020/12/18出院，病患住院'\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(disease=_disease,doc=_doc,ans='')\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
        "res=tokenizer.batch_decode(outputs)\n",
        "res[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "G37lp_4FOSOB",
        "outputId": "9a940e6d-d379-4650-d800-98fb9c9d81e7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n任務：從\"診斷病名\"與\"醫囑\"推論病患可能施行過那些\"醫療手術\"?\\n提示：這是個多標籤分類任務: multi-label task，醫療手術可能0到多個手術\\n\\n### Input:\\n診斷病名:\\n懷孕39週，早期破水胎位不正，剖腹產(以下空白)\\n醫囑:\\n於109年12月18日入院，於109年12月19日接受剖腹產，109年12月13日出院，共計6天.(以下空白)\\n\\n### Response:\\n有妊娠併發症之剖腹產術<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_dataset.data[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE8kfSLOOSC6",
        "outputId": "32d52661-6cfd-40b8-f7d2-b3d77eb9f56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.StringScalar: 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n任務：從\"診斷病名\"與\"醫囑\"推論病患可能施行過那些\"醫療手術\"?\\n提示：這是個多標籤分類任務: multi-label task，醫療手術可能0到多個手術\\n\\n### Input:\\n診斷病名:\\n妊娠38+3週合併胎位不正~(以下空白)\\n醫囑:\\n病患因上述原因於民國109年11月30日在本院住院，於民國109年12月01日剖腹生產，於民國109年12月06日出院，宜於門診持續追蹤治療~(以下空白)\\n\\n### Response:\\n有妊娠併發症之剖腹產術<|eot_id|>'>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EpFXYMJgOR9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qBRykMCGraDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNIhJMX1DWA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "aa7f7196-aba2-4226-a9fd-9aec8295c77d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7fe53d5bb1c0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1280\"\n",
              "            height=\"768\"\n",
              "            src=\"https://www.youtube.com/embed/ifCDXFdeaaM\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('ifCDXFdeaaM', width=1280, height=768)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b36Rqtd9XoRn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db3e51e0a8d244d7a53e9d50d2fce38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d2c67d0758846c393fc8cbead19d456",
              "IPY_MODEL_6b1d2a8a16524835b5e0b766beb4050f",
              "IPY_MODEL_dcbd154bfbdc40edac55be9ab3843160"
            ],
            "layout": "IPY_MODEL_c3bdacc96a6d4182b795b5f4dceefcf3"
          }
        },
        "1d2c67d0758846c393fc8cbead19d456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27d88911ded34b5682a288af1fd589e3",
            "placeholder": "​",
            "style": "IPY_MODEL_d758b1d96ad44a808bfaf8367c6d2cf6",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6b1d2a8a16524835b5e0b766beb4050f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68787eff1105466a936f7fdc0407d6d1",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85bcd726079141f7ab4ce909629279a5",
            "value": 4
          }
        },
        "dcbd154bfbdc40edac55be9ab3843160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f20eeae80ac4e2d966844592b9dec01",
            "placeholder": "​",
            "style": "IPY_MODEL_d45add3904234898bd48ea7fee34b706",
            "value": " 4/4 [01:21&lt;00:00, 17.55s/it]"
          }
        },
        "c3bdacc96a6d4182b795b5f4dceefcf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27d88911ded34b5682a288af1fd589e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d758b1d96ad44a808bfaf8367c6d2cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68787eff1105466a936f7fdc0407d6d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85bcd726079141f7ab4ce909629279a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f20eeae80ac4e2d966844592b9dec01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d45add3904234898bd48ea7fee34b706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ce5f5f73c2a4234bbe185fd41b49c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6dcf66294c84140b70a97efdd1a4a08",
              "IPY_MODEL_59346db034ff48f290df7b8e172a296c",
              "IPY_MODEL_1a5226cb80674f5bbdc4995e4e280615"
            ],
            "layout": "IPY_MODEL_c21481dd9bd34c7ab6363b5540538d31"
          }
        },
        "b6dcf66294c84140b70a97efdd1a4a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8fa2a0ee6904539a28be2ac68de2f0a",
            "placeholder": "​",
            "style": "IPY_MODEL_41067882276e4ccb8c307b50f5dd1240",
            "value": "README.md: 100%"
          }
        },
        "59346db034ff48f290df7b8e172a296c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72d3b6b36adc439f8d3a4a30c2a2e6bd",
            "max": 5181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90257f549711488c93745fb1b6d2d74a",
            "value": 5181
          }
        },
        "1a5226cb80674f5bbdc4995e4e280615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a340fed4f747deb38d8ac4fd3ce53b",
            "placeholder": "​",
            "style": "IPY_MODEL_eecfef45bf3e4440885b4c19b23034ba",
            "value": " 5.18k/5.18k [00:00&lt;00:00, 337kB/s]"
          }
        },
        "c21481dd9bd34c7ab6363b5540538d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8fa2a0ee6904539a28be2ac68de2f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41067882276e4ccb8c307b50f5dd1240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72d3b6b36adc439f8d3a4a30c2a2e6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90257f549711488c93745fb1b6d2d74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0a340fed4f747deb38d8ac4fd3ce53b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eecfef45bf3e4440885b4c19b23034ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5503aac04d4c48a8b1551427e74bf9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e1027e0e0d4474b8be12c55d7aba0c2",
              "IPY_MODEL_37bd70a51c93480e9b4b4cf11d3c17dc",
              "IPY_MODEL_4d56cc1134b34e81ac0f29601ad7c5fe"
            ],
            "layout": "IPY_MODEL_41f4cda132c248b1b6b437d83f1e45c1"
          }
        },
        "8e1027e0e0d4474b8be12c55d7aba0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab1cfd0ef024464b61e4076f83472d0",
            "placeholder": "​",
            "style": "IPY_MODEL_d67609726aba4bc6a0feeef47cdbba63",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "37bd70a51c93480e9b4b4cf11d3c17dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43e8a32a4d4549968d5e38514bd3d217",
            "max": 167832240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ede50eef0cd420c81bfd4fb99d040d0",
            "value": 167832240
          }
        },
        "4d56cc1134b34e81ac0f29601ad7c5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8a7ebcea0684bc0b486859871edf1cd",
            "placeholder": "​",
            "style": "IPY_MODEL_84a7f27933e246c2ae59cdd4548dac8f",
            "value": " 168M/168M [00:06&lt;00:00, 34.8MB/s]"
          }
        },
        "41f4cda132c248b1b6b437d83f1e45c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab1cfd0ef024464b61e4076f83472d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d67609726aba4bc6a0feeef47cdbba63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43e8a32a4d4549968d5e38514bd3d217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ede50eef0cd420c81bfd4fb99d040d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8a7ebcea0684bc0b486859871edf1cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84a7f27933e246c2ae59cdd4548dac8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}